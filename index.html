<!--
 * @Author: Yu Liu liuyu20@mails.tsinghua.edu.cn
 * @Date: 2023-01-30 
 * @LastEditors: Yu Liu liuyu20@mails.tsinghua.edu.cn
 * @LastEditTime: 2023-01-30
 * @FilePath: \yuLiu-ly.github.io\index.html
 * @Description: This is the Web Page of Yu Liu
-->
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yu Liu @ THU</title>

  <meta name="author" content="Yu Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="msvalidate.01" content="1D6EAEB9C6558C0BB977413398D67E91" />
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/icon.png">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Yu Liu </name><chname> (刘宇)</chname>
                  <h1></h1>
                  <img src="./images/Institution/tsinghua.png" alt style="height: 38px; margin-left: 10px;">
                  <img src="./images/Institution/bigai.png" alt style="height: 38px; margin-left: 10px;">
                  <img src="./images/Institution/THUAGI.png" alt style="height: 38px; margin-left: 10px;">
                </p>
                <p>
                    I'm Yu Liu, a second year Ph.D. student in <a href="https://www.au.tsinghua.edu.cn/" target="_blank">Department of Automation, Tsinghua University</a>, advised by <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>.
                    I obtained my bachelor's degree in engineering from the Department of Automation at Tsinghua University, as the monitor of the <a href="https://tongclass.ac.cn" target="_blank">Tong Class</a> (an AGI program founded by <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>). 
                    I'm currently working at General Vision Lab in <a href="https://www.bigai.ai/" target="_blank">BIGAI</a> (Beijing Institute for General Artificial Intelligence) as a research intern 
                    advised by <a href="https://buzz-beater.github.io" target="_blank">Dr. Baoxiong Jia</a> and <a href="https://siyuanhuang.com/" target="_blank">Dr. Siyuan Huang</a>.
                </p>
                <p>
                    I'm also the chairman of THUAGI (Tsinghua University Artificial General Intelligence Student Association), a student society that aims to provide a platform for students, AI researchers, and industry professionals to meet new friends, exchange ideas and collaborate. 
                    Welcome to follow THUAGI's Wechat official account. If you have any cooperation intentions, feel free to add me on wechat to contact me. 
                </p>
                <p>
                    My research interest lies in computer vision and embodied AI, specifically 3D/4D reconstruction/generation and articulated object reconstruction/generation.
                    My hobbies are reading, music, natural scenery and meditation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:liuyu_ai@foxmail.com" target="_blank"><img
										src="./images/Icon/email.png" height="32px"
										style="margin-bottom:-4px"></a>&nbsp;&nbsp;
                  <a href="https://scholar.google.com/citations?user=t1-cWnoAAAAJ&hl=en" target="_blank"><img src="./images/Icon/google_scholar.png"
										height="32px"
										style="margin-bottom:-3px"></a>&nbsp;&nbsp;
                  <a href="https://github.com/yuLiu-ly/" target="_blank"><img src="./images/Icon/github.jpg"
										height="32px"
										style="margin-bottom:-3px"></a>&nbsp;&nbsp;
                  <a href="./images/Personal/mywechat.png" target="_blank"><img
                    src="./images/Icon/wechat.png"
                    height="32px" style="margin-bottom:-3px"></a>&nbsp;&nbsp;
                  <a href="https://www.xiaohongshu.com/user/profile/6592bb9e0000000022013766"
                    target="_blank"><img src="./images/Icon/xiaohongshu.png" height="32px"
                      style="margin-bottom:-4px"></a>&nbsp;&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/Personal/Yu1.jpg"><img style="width:150%;max-width:150%" alt="profile photo" src="images/Personal/Yu1.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
    </tbody></table>

    <!-- RESEARCH -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:30px;width:100%;vertical-align:middle;padding-bottom:0px;">
            <heading>Research</heading>
          </td>
        </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!-- VideoArtGS -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one" style="display: flex; align-items: center;">
            <video width="120%" height="auto" muted autoplay loop>
              <source src="images/Research/videoartgs.mp4" type="video/mp4">
            </video>
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>VideoArtGS: Building Digital Twins of Articulated Objects from Monocular Video</papertitle>
          <br>
          <strong>Yu Liu</strong>,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia</a>,
          <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
          <a href="https://github.com/Juliagan2004" target="_blank">Chuyue Gan</a>,
          <a href="https://github.com/HuayuChen2004" target="_blank">Huayu Chen</a>,
          <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">JunFeng Ni</a>,
          <a href="https://www.zhusongchun.net" target="_blank">Song-Chun Zhu</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>Preprint</em> 
          <br>
          <a href="https://arxiv.org/abs/2509.17647" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://videoartgs.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://github.com/YuLiu-LY/VideoArtGS" target="_blank">[Code]</a>
          <br>
          <abs>
            We introduce <strong>VideoArtGS</strong>, a novel approach that reconstructs high-fidelity digital twins of articulated objects from monocular video. VideoArtGS demonstrates SOTA performance in articulation and mesh reconstruction, reducing the reconstruction error by about two orders of magnitude compared to existing methods.
          </abs>
        </td>
      </tr>

      <!-- ArtGS -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/artgs.gif' width="190">
            </div>
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting</papertitle>
          <br>
          <strong>Yu Liu*</strong>,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
          <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">JunFeng Ni</a>,
          <a href="https://www.zhusongchun.net" target="_blank">Song-Chun Zhu</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ICLR</em> 2025
          <br>
          <a href="https://arxiv.org/abs/2502.19459" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://articulate-gs.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://github.com/YuLiu-LY/ArtGS" target="_blank">[Code]</a>
          <br>
          <abs>
            We introduce <strong>ArtGS</strong>, a novel approach that leverages 3D Gaussians to reconstruct articulated objects from 2 states of RGBD images, which achieves state-of-the-art performance in joint parameter estimation and part mesh reconstruction.
          </abs>
        </td>
      </tr>

      <!-- DP-Recon -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one" style="display: flex; align-items: center;">
            <video width="120%" height="auto" muted autoplay loop>
              <source src="images/Research/dprecon.mp4" type="video/mp4">
            </video>
          </div>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>Decompositional Neural Scene Reconstruction with Generative Diffusion Prior</papertitle>
              <br>
                <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a>,
                <strong>Yu Liu</strong>, 
                <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
                <a href="https://github.com/zr-zhou0o0" target="_blank">Zirui Zhou</a>,
                <a href="https://zhusongchun.net/" target="_blank">Song-Chun Zhu</a>, 
                <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
                <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
              <br>
              <em>CVPR</em> 2025
              <br>
              <a href="https://arxiv.org/abs/2503.14830" target="_blank">[Paper]</a>
              <a href="https://dp-recon.github.io/" target="_blank">[Project Page]</a>
              <a href="https://github.com/DP-Recon/DP-Recon" target="_blank">[Code]</a>
              <br>
              <abs>
                We introduce <strong>DP-Recon</strong>, a novel approach that distills off-the-shelf diffusion models for high-quality decompositional scene reconstruction from sparse view images. Further fine-grained editings are well supported.
              </abs>
        </td>
      </tr>


      <!-- TACO -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one" style="display: flex; align-items: center;">
            <video width="120%" height="auto" muted autoplay loop>
              <source src="images/Research/TACO.mp4" type="video/mp4">
            </video>
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>TACO: Taming Diffusion for in-the-wild Video Amodal Completion</papertitle>
              <br>
              <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
              <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
              <strong>Yu Liu</strong>,
            <a href="https://me.kiui.moe/" target="_blank">Jiaxiang Tang</a>,
              <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a>,
              <a href="https://github.com/dnvtmf" target="_blank">Diwen Wan</a>,
              <a href="https://www.cis.pku.edu.cn/info/1177/1378.htm" target="_blank">Gang Zeng</a>,
              <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
              <br>
              <em>ICCV</em> 2025 <font color='red'></font>
              <br>
              <a href="https://arxiv.org/abs/2503.12049" target="_blank">[Paper]</a>
              <a href="https://jason-aplp.github.io/Ruijie-Lu/TACO-code" target="_blank">[Code]</a>
              <a href="https://huggingface.co/datasets/JasonAplp/TACO_training_dataset" target="_blank">[Data]</a>
              <a href="https://jason-aplp.github.io/TACO/" target="_blank">[Project Page]</a>
              <br>
              <abs>
                We introduce <strong>TACO</strong>, which repurposes pre-trained video diffusion models for Video Amodal Completion (VAC), facilitating downstream tasks like reconstruction. The key insight lies in the data curation and progressive training strategy. 
              </abs>
        </td>
      </tr>
      

      <!-- MOVIS -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_stop()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:20px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/movis.png' width="190">
            </div>
          </div>
          <script type="text/javascript">
            function scenediffuser_stop() {
              document.getElementById('MOVIS_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('MOVIS_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</papertitle>
          <br>
          <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu*</a>,
          <a href="https://yixchen.github.io/" target="_blank">Yixin Chen*</a>,
          <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a >,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia</a >,
          <strong>Yu Liu</strong>,
          <a href="https://github.com/dnvtmf" target="_blank">Diwen Wan</a >,
          <a href="https://www.cis.pku.edu.cn/info/1177/1378.htm" target="_blank">Gang Zeng</a >,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a >
          <br>
          <em>CVPR</em> 2025 <font color='red'></font>
          <br>
          <a href="https://arxiv.org/abs/2412.11457" target="_blank">[Paper]</a >
          <a href="https://jason-aplp.github.io/Ruijie-Lu/MOVIS-code" target="_blank">[Code]</a >
          <a href="https://huggingface.co/datasets/JasonAplp/MOVIS" target="_blank">[Data]</a >
          <a href="https://jason-aplp.github.io/MOVIS/" target="_blank">[Project Page]</a >
          <br>
          <abs>
            We introduce <strong>MOVIS</strong>, which repurposes pre-trained diffusion models for multi-object level novel view synthesis (NVS) in indoor scenes. The key insight lies in incorporating a structure-aware noise scheduler and an auxiliary mask prediction task under novel views.
          </abs>
        </td>
      </tr>
      
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/slotlifter.png' width="190"></div>
            <img src='images/Research/slotlifter.png' width="190">
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields</papertitle>
          <br>
          <strong>Yu Liu*</strong>,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ECCV</em> 2024
          <br>
          <a href="https://arxiv.org/abs/2408.06697" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://slotlifter.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://slotlifter.github.io/" target="_blank">[Code]</a>
          <br>
          <abs>
           We propose <strong>SlotLifter</strong>, a novel object-centric radiance model that aims to address the challenges of scene reconstruction and decomposition via slot-guided feature lifting.
          </abs>
        </td>
      </tr>

      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/overview_new.png' width="190"></div>
            <img src='images/Research/overview_new.png' width="190">
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:top;padding-bottom:0px;">
          <papertitle>Improving Object-centric Learning With Query Optimization</papertitle>
          <br>
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <strong>Yu Liu*</strong>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ICLR</em> 2023
          <br>
          <a href="https://arxiv.org/abs/2210.08990" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://bo-qsa.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://github.com/YuLiu-LY/BO-QSA" target="_blank">[Code]</a>
          <br>
          <abs>
            We proposed <strong>BO-QSA</strong> for (1) initializing Slot-Attention modules with learnable queries and 
            (2) optimizing the model with bi-level optimization. 
          </abs>
        </td>
      </tr>

    </tbody></table>
    
    <!-- EXPERIENCE -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:30px;width:100%;vertical-align:middle;padding-top:40px;">
          <heading>Experience</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <tr>
        <td style="padding:30px;width:18px;vertical-align:middle"><img src="images/Institution/tsinghua.png", width="150px"></td>
        <td width="90%" valign="center">
          <b>Tsinghua University</b>, China
          <br> 2024.08 - now
          <br>
          <br> <b>Ph.D. Student</b>
          <br> Advisor:  <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>
        </td>
      </tr>
      <tr>
        <td style="padding:30px;width:18px;vertical-align:middle"><img src="images/Institution/tsinghua.png", width="150px"></td>
        <td width="90%" valign="center">
          <b>Tsinghua University</b>, China
          <br> 2020.08 - 2024.07
          <br>
          <br> <b>Undergraduate Student</b>
          <br> Advisor:  <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>
        </td>
      </tr>
      <tr>
        <td style="padding:30px;width:18px;vertical-align:middle"><img src="images/Institution/bigai.png", width="150px"></td>
        <td width="90%" valign="center">
          <b>Beijing Institute for General Artificial Intelligence(BIGAI)</b>, China
          <br> 2021.09 - now
          <br>
          <br> <b>Research Intern</b>
          <br> Advisor: <a href="https://buzz-beater.github.io/">Dr. Baoxiong Jia</a> and <a href="https://siyuanhuang.com/" target="_blank">Dr. Siyuan Huang</a>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:30px;width:100%;vertical-align:middle;padding-top:40px;">
          <heading>Selected Awards and Honors</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <ul>
        <li>Tsinghua University outstanding undergraduate thesis</li>
        <li>Student of the Year 2023, Department of Automation, Tsinghua University</li>
        <li>Comprehensive Excellence Award of Tsinghua University (2020 & 2022)</li>
        <li>Science and Technology Innovation Excellence Award of Tsinghua University (2021)</li>
        <li>Research Star Award, Beijing Institute for General Artificial Intelligence(BIGAI)</li>
        <li>Huang Yicong Scholarship, Research Excellence Award</li>
      </ul>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
          Thanks for your visiting by &#128522.
          <br>
          Template stolen from <a href="https://jonbarron.info/" style="text-align:right;font-size:small;" target="_blank">Jon Barron</a>. 
          Page icon made by <a href="https://www.flaticon.com/authors/freepik" style="text-align:right;font-size:small;" target="_blank">Freepik</a>
          from <a href="https://www.flaticon.com/" style="text-align:right;font-size:small;" target="_blank">flaticon.com</a> .
          <!-- <br> 
          Last updated: Oct. 6, 2022 -->
          </p>
        </td>
      </tr>
    </tbody></table>
  </td>
  </tr>
  </table>
</body>

</html>
