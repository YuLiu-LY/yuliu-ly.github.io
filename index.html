<!--
 * @Author: Yu Liu liuyu20@mails.tsinghua.edu.cn
 * @Date: 2023-01-30 
 * @LastEditors: Yu Liu liuyu20@mails.tsinghua.edu.cn
 * @LastEditTime: 2023-01-30
 * @FilePath: \yuLiu-ly.github.io\index.html
 * @Description: This is the Web Page of Yu Liu
-->
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yu Liu @ THU</title>

  <meta name="author" content="Yu Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="msvalidate.01" content="1D6EAEB9C6558C0BB977413398D67E91" />
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/icon.png">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Yu Liu </name><chname> (刘宇)</chname>
                </p>
                <p>
                    I'm Yu Liu, a first year Ph.D. student in <a href="https://www.au.tsinghua.edu.cn/" target="_blank">Department of Automation, Tsinghua University</a>, advised by <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>.
                    I obtained my bachelor's degree in engineering from the Department of Automation at Tsinghua University, as the monitor of the <a href="https://tongclass.ac.cn" target="_blank">Tong Class</a> (an AGI program founded by <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>). 
                    I'm currently working at General Vision Lab in <a href="https://www.bigai.ai/" target="_blank">BIGAI</a> (Beijing Institute for General Artificial Intelligence) as a research intern 
                    advised by <a href="https://buzz-beater.github.io" target="_blank">Dr. Baoxiong Jia</a> and <a href="https://siyuanhuang.com/" target="_blank">Dr. Siyuan Huang</a>.
                    
                </p>
                <p>
                    My research interest lies in computer vision, specifically unsupervised object-centric learning, articulated object reconstruction and 3D/4D reconstruction/generation.
                    My hobbies are reading, music, natural scenery and meditation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:liuyu_ai@foxmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=t1-cWnoAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/yuLiu-ly/" target="_blank">Github</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/Personal/Yu1.jpg"><img style="width:150%;max-width:150%" alt="profile photo" src="images/Personal/Yu1.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
    </tbody></table>

    <!-- RESEARCH -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:30px;width:100%;vertical-align:middle;padding-bottom:0px;">
            <heading>Research</heading>
          </td>
        </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <!-- ArtGS -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/artgs.gif' width="190">
            </div>
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting</papertitle>
          <br>
          <strong>Yu Liu*</strong>,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
          <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">JunFeng Ni</a>,
          <a href="https://www.zhusongchun.net" target="_blank">Song-Chun Zhu</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ICLR</em> 2025
          <br>
          <a href="https://arxiv.org/abs/2502.19459" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://articulate-gs.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://github.com/YuLiu-LY/ArtGS" target="_blank">[Code]</a>
          <br>
          <abs>
            We introduce <strong>ArtGS</strong>, a novel approach that leverages 3D Gaussians to reconstruct articulated objects from 2 states of RGBD images, which achieves state-of-the-art performance in joint parameter estimation and part mesh reconstruction.
          </abs>
        </td>
      </tr>

      <!-- DP-Recon -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one" style="display: flex; align-items: center;">
            <video width="120%" height="auto" muted autoplay loop>
              <source src="images/Research/dprecon.mp4" type="video/mp4">
            </video>
          </div>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>Decompositional Neural Scene Reconstruction with Generative Diffusion Prior</papertitle>
              <br>
                <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a>,
                <strong>Yu Liu</strong>, 
                <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
                <a href="https://github.com/zr-zhou0o0" target="_blank">Zirui Zhou</a>,
                <a href="https://zhusongchun.net/" target="_blank">Song-Chun Zhu</a>, 
                <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
                <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
              <br>
              <em>CVPR</em> 2025
              <br>
              <a href="https://arxiv.org/abs/2503.14830" target="_blank">[Paper]</a>
              <a href="https://dp-recon.github.io/" target="_blank">[Project Page]</a>
              <a href="https://github.com/DP-Recon/DP-Recon" target="_blank">[Code]</a>
              <br>
              <abs>
                We introduce <strong>DP-Recon</strong>, a novel approach that distills off-the-shelf diffusion models for high-quality decompositional scene reconstruction from sparse view images. Further fine-grained editings are well supported.
              </abs>
        </td>
      </tr>


      <!-- TACO -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one" style="display: flex; align-items: center;">
            <video width="120%" height="auto" muted autoplay loop>
              <source src="images/Research/TACO.mp4" type="video/mp4">
            </video>
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>TACO: Taming Diffusion for in-the-wild Video Amodal Completion</papertitle>
              <br>
              <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu</a>,
              <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
              <strong>Yu Liu</strong>,
            <a href="https://me.kiui.moe/" target="_blank">Jiaxiang Tang</a>,
              <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a>,
              <a href="https://github.com/dnvtmf" target="_blank">Diwen Wan</a>,
              <a href="https://www.cis.pku.edu.cn/info/1177/1378.htm" target="_blank">Gang Zeng</a>,
              <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
              <br>
              <em>ICCV</em> 2025 <font color='red'></font>
              <br>
              <a href="https://arxiv.org/abs/2503.12049" target="_blank">[Paper]</a>
              <a href="https://jason-aplp.github.io/Ruijie-Lu/TACO-code" target="_blank">[Code]</a>
              <a href="https://huggingface.co/datasets/JasonAplp/TACO_training_dataset" target="_blank">[Data]</a>
              <a href="https://jason-aplp.github.io/TACO/" target="_blank">[Project Page]</a>
              <br>
              <abs>
                We introduce <strong>TACO</strong>, which repurposes pre-trained video diffusion models for Video Amodal Completion (VAC), facilitating downstream tasks like reconstruction. The key insight lies in the data curation and progressive training strategy. 
              </abs>
        </td>
      </tr>
      

      <!-- MOVIS -->
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_stop()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:20px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/movis.png' width="190">
            </div>
          </div>
          <script type="text/javascript">
            function scenediffuser_stop() {
              document.getElementById('MOVIS_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('MOVIS_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes</papertitle>
          <br>
          <a href="https://jason-aplp.github.io/Ruijie-Lu" target="_blank">Ruijie Lu*</a>,
          <a href="https://yixchen.github.io/" target="_blank">Yixin Chen*</a>,
          <a href="https://dali-jack.github.io/Junfeng-Ni/" target="_blank">Junfeng Ni</a >,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia</a >,
          <strong>Yu Liu</strong>,
          <a href="https://github.com/dnvtmf" target="_blank">Diwen Wan</a >,
          <a href="https://www.cis.pku.edu.cn/info/1177/1378.htm" target="_blank">Gang Zeng</a >,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a >
          <br>
          <em>CVPR</em> 2025 <font color='red'></font>
          <br>
          <a href="https://arxiv.org/abs/2412.11457" target="_blank">[Paper]</a >
          <a href="https://jason-aplp.github.io/Ruijie-Lu/MOVIS-code" target="_blank">[Code]</a >
          <a href="https://huggingface.co/datasets/JasonAplp/MOVIS" target="_blank">[Data]</a >
          <a href="https://jason-aplp.github.io/MOVIS/" target="_blank">[Project Page]</a >
          <br>
          <abs>
            We introduce <strong>MOVIS</strong>, which repurposes pre-trained diffusion models for multi-object level novel view synthesis (NVS) in indoor scenes. The key insight lies in incorporating a structure-aware noise scheduler and an auxiliary mask prediction task under novel views.
          </abs>
        </td>
      </tr>
      
      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/slotlifter.png' width="190"></div>
            <img src='images/Research/slotlifter.png' width="190">
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:middle;padding-bottom:0px;">
          <papertitle>SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields</papertitle>
          <br>
          <strong>Yu Liu*</strong>,
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ECCV</em> 2024
          <br>
          <a href="https://arxiv.org/abs/2408.06697" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://slotlifter.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://slotlifter.github.io/" target="_blank">[Code]</a>
          <br>
          <abs>
           We propose <strong>SlotLifter</strong>, a novel object-centric radiance model that aims to address the challenges of scene reconstruction and decomposition via slot-guided feature lifting.
          </abs>
        </td>
      </tr>

      <tr onmouseout="scenediffuser_stop()" onmouseover="scenediffuser_start()">
        <td style="padding:30px;width:25%;vertical-align:middle;padding-top:40px;padding-bottom:0px;">
          <div class="one">
            <div class="two" id='scenediffuser_image'>
              <img src='images/Research/overview_new.png' width="190"></div>
            <img src='images/Research/overview_new.png' width="190">
          </div>
          <script type="text/javascript">
            function scenediffuser_start() {
              document.getElementById('scenediffuser_image').style.opacity = "1";
            }

            function scenediffuser_stop() {
              document.getElementById('scenediffuser_image').style.opacity = "0";
            }
            scenediffuser_stop()
          </script>
        </td>
        <td style="padding:30px;width:75%;vertical-align:top;padding-bottom:0px;">
          <papertitle>Improving Object-centric Learning With Query Optimization</papertitle>
          <br>
          <a href="https://buzz-beater.github.io/" target="_blank">Baoxiong Jia*</a>,
          <strong>Yu Liu*</strong>,
          <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a>
          <br>
          <em>ICLR</em> 2023
          <br>
          <a href="https://arxiv.org/abs/2210.08990" target="_blank">[Paper]</a>
          &nbsp
          <a href="https://bo-qsa.github.io/" target="_blank">[Project Page]</a>
          &nbsp
          <a href="https://github.com/YuLiu-LY/BO-QSA" target="_blank">[Code]</a>
          <br>
          <abs>
            We proposed <strong>BO-QSA</strong> for (1) initializing Slot-Attention modules with learnable queries and 
            (2) optimizing the model with bi-level optimization. 
          </abs>
        </td>
      </tr>

    </tbody></table>
    
    <!-- EXPERIENCE -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:30px;width:100%;vertical-align:middle;padding-top:40px;">
          <heading>Experience</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/tsinghua.svg", width="100px"></td>
        <td width="90%" valign="center">
          <b>Tsinghua University</b>, China
          <br> 2024.08 - now
          <br>
          <br> <b>Ph.D. Student</b>
          <br> Advisor:  <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>
        </td>
      </tr>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/tsinghua.svg", width="100px"></td>
        <td width="90%" valign="center">
          <b>Tsinghua University</b>, China
          <br> 2020.08 - 2024.07
          <br>
          <br> <b>Undergraduate Student</b>
          <br> Advisor:  <a href="https://www.zhusongchun.net" target="_blank">Prof. Song-Chun Zhu</a>
        </td>
      </tr>
      <tr>
        <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bigai.png", width="100px"></td>
        <td width="90%" valign="center">
          <b>Beijing Institute for General Artificial Intelligence(BIGAI)</b>, China
          <br> 2021.09 - now
          <br>
          <br> <b>Research Intern</b>
          <br> Advisor: <a href="https://buzz-beater.github.io/">Dr. Baoxiong Jia</a> and <a href="https://siyuanhuang.com/" target="_blank">Dr. Siyuan Huang</a>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:30px;width:100%;vertical-align:middle;padding-top:40px;">
          <heading>Selected Awards and Honors</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <ul>
        <li>Tsinghua University outstanding undergraduate thesis</li>
        <li>Student of the Year 2023, Department of Automation, Tsinghua University</li>
        <li>Tsinghua University Comprehensive Excellent Award (2020 & 2022)</li>
        <li>Tsinghua Science and Technology Innovation Excellence Award (2021)</li>
        <li>Research Star Award, Beijing Institute for General Artificial Intelligence(BIGAI)</li>
        <li>Huang Yicong Scholarship, Research Excellence Award</li>
      </ul>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
          Thanks for your visiting by &#128522.
          <br>
          Template stolen from <a href="https://jonbarron.info/" style="text-align:right;font-size:small;" target="_blank">Jon Barron</a>. 
          Page icon made by <a href="https://www.flaticon.com/authors/freepik" style="text-align:right;font-size:small;" target="_blank">Freepik</a>
          from <a href="https://www.flaticon.com/" style="text-align:right;font-size:small;" target="_blank">flaticon.com</a> .
          <!-- <br> 
          Last updated: Oct. 6, 2022 -->
          </p>
        </td>
      </tr>
    </tbody></table>
  </td>
  </tr>
  </table>
</body>

</html>
